# gpt2
This repository is dedicated to the development of GPT2 (124 million parameter model) from scratch using the tutorial of Andrej Karpathy - https://www.youtube.com/watch?v=l8pRSuU81PU. The paper pertaining to this gpt2 is titled "Language Models are Unsupervised Multitask Learners".
